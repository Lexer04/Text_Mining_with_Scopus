word,x_values,y_values,count
",",12.601091,4.8288,88166
.,17.285076,3.652901,89793
),12.531593,9.51871,19343
(,15.059682,8.950083,18942
â©,18.768312,6.876808,9761
learning,27.243868,-9.580318,7016
data,22.954578,1.6961857,7567
proposed,27.32415,-34.37386,8638
network,20.631622,1.7574972,5320
model,22.060667,-34.556168,7154
algorithm,27.807146,-51.58124,4062
networks,22.704266,23.96489,2685
performance,26.112707,-29.784386,4885
results,29.095749,-32.1354,6253
based,17.886868,-23.842054,5700
paper,20.111149,-0.47094643,5439
system,15.165997,1.9685489,3654
problem,24.829008,-23.253063,2663
using,16.095682,-26.383324,6259
method,25.145493,-42.665726,7753
different,22.688993,-4.395321,4041
systems,15.307951,36.389095,2263
also,16.00382,-6.081199,3193
time,23.429693,-23.836407,2063
used,16.380127,-15.672683,4776
research,22.946888,31.403034,2161
approach,20.821484,-29.212803,3678
neural,36.451866,-11.338708,3998
models,20.895988,-18.913359,3516
ieee,27.25968,11.633261,2687
methods,20.330498,-22.483135,5749
%,49.362762,-29.029757,4778
show,25.556519,-40.152786,3085
information,19.308756,6.7172284,4144
deep,35.50708,-7.4788575,4415
new,18.617533,5.225478,2824
algorithms,22.697111,-29.709982,2428
:,17.295698,3.8181975,3089
propose,28.513441,-15.698063,3096
however,20.405607,8.391022,2569
two,21.497002,-17.67271,3116
applications,20.957735,41.665585,2174
techniques,16.539062,2.5298333,2149
use,15.168405,7.700122,2409
study,16.790138,-4.3691645,1915
framework,19.061022,-15.353812,2062
task,23.489328,-25.638424,1718
machine,31.596783,4.1762547,1668
one,19.12827,10.09091,2107
process,18.726698,-13.667843,1654
work,16.922422,-2.7927063,2071
multiple,22.049978,10.971703,1457
tasks,22.2144,-12.246288,1534
compared,24.796593,-35.532536,2037
existing,22.649055,-5.0336256,2073
various,18.043213,10.617777,1737
number,18.677217,-2.3379304,1447
2022,19.73191,17.473846,1472
improve,27.213121,-14.294388,1666
analysis,17.922483,-14.91921,2454
first,19.347368,-11.815614,1940
due,22.188343,23.296864,1487
high,26.389284,0.9711572,1917
approaches,20.830574,-17.953606,1822
novel,24.48621,-12.26553,2202
accuracy,31.20076,-40.45903,4258
well,16.009779,-2.50555,1501
present,19.027094,-4.008452,1687
rights,45.926632,52.505577,1528
training,25.864485,-28.515734,3092
human,16.968546,4.7465634,2168
reserved,46.67715,50.474686,1546
better,22.730408,-27.276295,1673
many,18.53078,21.655203,1684
demonstrate,24.731966,-35.63193,1763
experiments,24.715258,-33.079304,2226
set,20.985943,-21.335905,1729
features,20.781172,-10.701319,4971
three,21.25064,-13.614829,1477
processing,15.601834,13.863939,1736
experimental,23.592686,-22.223444,2304
detection,20.86103,-6.2128415,4720
state-of-the-art,27.82609,-27.515102,2077
classification,22.668663,-25.720978,3953
image,24.310394,-14.212108,8854
dataset,22.024914,-19.115858,2602
datasets,23.10078,-17.120077,2245
local,18.75834,-12.755429,1513
video,17.350483,1.4773854,2043
feature,22.891129,-16.69308,4152
images,18.462183,-3.4703631,7317
recognition,19.271273,-2.5687668,4861
convolutional,28.117191,-1.2932283,1986
representation,21.029158,-13.376804,1482
object,18.609793,-9.818741,2453
visual,16.255905,1.8700294,2011
face,16.979982,4.3399706,2057
cnn,21.685495,-12.083536,1674
3d,15.072686,-0.88343114,2004
segmentation,18.53023,-12.084045,2865
